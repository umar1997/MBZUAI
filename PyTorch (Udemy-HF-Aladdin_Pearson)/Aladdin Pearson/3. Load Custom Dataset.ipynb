{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Load Custom Dataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMcs7pGkzfpDH22mxWYYgia"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install -U torchtext==0.8.0\n","# !pip install -U torchtext==0.6.0 # This worked"],"metadata":{"id":"dDxUwlol2PHu","executionInfo":{"status":"ok","timestamp":1643644738381,"user_tz":-240,"elapsed":7,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import spacy\n","from torchtext.data import Field, TabularDataset, BucketIterator, Iterator"],"metadata":{"id":"oCubCQBu2FIQ","executionInfo":{"status":"ok","timestamp":1643644755592,"user_tz":-240,"elapsed":831,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["######### Loading from JSON/CSV/TSV files #########\n","\n","# STEPS:\n","# 1. Specify how preprocessing should be done -> Fields\n","# 2. Use Dataset to load the data -> TabularDataset (JSON/CSV/TSV Files)\n","# 3. Construct an iterator to do batching & padding -> BucketIterator"],"metadata":{"id":"vazxYMDs3zM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjePxTox3fDG","executionInfo":{"status":"ok","timestamp":1643644873419,"user_tz":-240,"elapsed":26898,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"95bf4fe6-dbf3-456e-9736-bf93f32d7baa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}]},{"cell_type":"code","source":["import os\n","import zipfile\n","import numpy as np\n","\n","dir = \"/content/drive/My Drive/Colab Notebooks/PyTorch/Aladdin Pearson/Data/\"\n","files = os.listdir(dir)\n","files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-yB-XRf3lpY","executionInfo":{"status":"ok","timestamp":1643644937119,"user_tz":-240,"elapsed":9,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"e2f139f2-4d40-4acb-a526-74d6c09ec06b"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['train.csv', 'test.csv', 'test.json', 'train.json']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CX67ISaj34_h","executionInfo":{"status":"ok","timestamp":1643644955877,"user_tz":-240,"elapsed":12,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"2c888a08-b1e3-47a2-aea8-e4689b730ee5"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# python -m spacy download en\n","spacy_en = spacy.load(\"en\")"],"metadata":{"id":"QYFKeADt4Cl4","executionInfo":{"status":"ok","timestamp":1643644995076,"user_tz":-240,"elapsed":1966,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["tokenize = lambda x: x.split()\n","\n","# def tokenize(text):\n","#     return [tok.text for tok in spacy_en.tokenizer(text)]"],"metadata":{"id":"wGZh16UU5XBA","executionInfo":{"status":"ok","timestamp":1643645404036,"user_tz":-240,"elapsed":844,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["quote = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n","score = Field(sequential=False, use_vocab=False)\n","\n","fields = {\"quote\": (\"q\", quote), \"score\": (\"s\", score)} \n","# When want to get the batches we will use batch.q\n","\n","train_data, test_data = TabularDataset.splits(\n","                    path= dir, \n","                    train=\"train.json\", \n","                    test=\"test.json\",\n","                    format=\"json\", \n","                    # validation = \"validation.json\" \n","                    fields=fields\n",")\n","\n","# # train_data, test_data = TabularDataset.splits(\n","# #                                         path='mydata',\n","# #                                         train='train.csv',\n","# #                                         test='test.csv',\n","# #                                         format='csv',\n","# #                                         fields=fields)\n","\n","quote.build_vocab(train_data, max_size=10000, min_freq=1, vectors=\"glove.6B.100d\")\n","# min_freq=2 of atleast 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZWtPPul5Aj1","executionInfo":{"status":"ok","timestamp":1643645629920,"user_tz":-240,"elapsed":215440,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"0776c458-956b-4fad-a86b-55c9c776460b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  self.sequential = sequential\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  ex = cls()\n",".vector_cache/glove.6B.zip: 862MB [02:40, 5.36MB/s]                           \n","100%|█████████▉| 399999/400000 [00:19<00:00, 20420.76it/s]\n"]}]},{"cell_type":"code","source":["train_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, test_data), batch_size=2, device=device\n",")\n","\n","# Iterator to do the batching and the padding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kyb79-N97kY","executionInfo":{"status":"ok","timestamp":1643646534162,"user_tz":-240,"elapsed":12,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"474e6682-c3f9-44fb-ad82-34911ea4b352"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  sort_within_batch=None):\n"]}]},{"cell_type":"code","source":["for batch in train_iterator:\n","  print(batch.q)\n","  print(batch.s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2mMqdh2-Qr6","executionInfo":{"status":"ok","timestamp":1643646713544,"user_tz":-240,"elapsed":10,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"4bd7523b-716c-4a79-c8d5-b1d8c1d68798"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[10, 27],\n","        [21, 29],\n","        [ 4,  7],\n","        [ 3, 26],\n","        [ 6, 18],\n","        [11,  2],\n","        [17, 25],\n","        [ 4,  1],\n","        [ 3,  1],\n","        [30,  1],\n","        [28,  1],\n","        [ 5,  1],\n","        [13,  1],\n","        [ 2,  1],\n","        [ 9,  1],\n","        [23,  1]])\n","tensor([1, 0])\n","tensor([[33],\n","        [19],\n","        [24],\n","        [14],\n","        [15],\n","        [34],\n","        [32],\n","        [31],\n","        [16],\n","        [20],\n","        [22],\n","        [12],\n","        [ 5],\n","        [ 8]])\n","tensor([1])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  self.batch_size = len(data)\n"]}]},{"cell_type":"code","source":["######### Training a simple LSTM on this toy data of ours #########\n","class RNN_LSTM(nn.Module):\n","    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n","        super(RNN_LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        self.embedding = nn.Embedding(input_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n","        self.fc_out = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        # Set initial hidden and cell states\n","        h0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n","\n","        embedded = self.embedding(x)\n","        outputs, _ = self.lstm(embedded, (h0, c0))\n","        prediction = self.fc_out(outputs[-1, :, :])\n","\n","        return prediction\n","\n","\n"],"metadata":{"id":"GOXy__4a2AoE","executionInfo":{"status":"ok","timestamp":1643647112794,"user_tz":-240,"elapsed":324,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","input_size = len(quote.vocab)\n","hidden_size = 512\n","num_layers = 2\n","embedding_size = 100\n","learning_rate = 0.005\n","num_epochs = 10"],"metadata":{"id":"nKapFYS9_2Bk","executionInfo":{"status":"ok","timestamp":1643647117807,"user_tz":-240,"elapsed":317,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Initialize network\n","model = RNN_LSTM(input_size, embedding_size, hidden_size, num_layers).to(device)\n","\n","# (NOT COVERED IN YOUTUBE VIDEO): Load the pretrained embeddings onto our model\n","pretrained_embeddings = quote.vocab.vectors\n","model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrBd4lRs_0UN","executionInfo":{"status":"ok","timestamp":1643647126116,"user_tz":-240,"elapsed":320,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"abc19b1e-c112-40df-d30f-b1591e9a8541"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.4989,  0.7660,  0.8975,  ..., -0.4118,  0.4054,  0.7850],\n","        [-0.5718,  0.0463,  0.8673,  ..., -0.3566,  0.9293,  0.8995]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# Loss and optimizer\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"BYixo2dM_4VM","executionInfo":{"status":"ok","timestamp":1643647134326,"user_tz":-240,"elapsed":527,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Train Network\n","for epoch in range(num_epochs):\n","    for batch_idx, batch in enumerate(train_iterator):\n","        # Get data to cuda if possible\n","        data = batch.q.to(device=device)\n","        targets = batch.s.to(device=device)\n","\n","        # forward\n","        scores = model(data)\n","        loss = criterion(scores.squeeze(1), targets.type_as(scores))\n","\n","        # backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent\n","        optimizer.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzH6Uhvm_nBF","executionInfo":{"status":"ok","timestamp":1643647139960,"user_tz":-240,"elapsed":3539,"user":{"displayName":"Umar Salman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHZcOsjv11SLF2pszrnnYSQho-DRZsHsPpvm1oXQ=s64","userId":"02559536710924243729"}},"outputId":"c8b2a1c1-c8c4-4c01-e418-a95ba4f6b1f7"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  self.batch_size = len(data)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"_ftQc2chAO9p"},"execution_count":null,"outputs":[]}]}