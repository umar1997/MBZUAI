{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912b8cb7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e5ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c18c8c",
   "metadata": {},
   "source": [
    "### Task 1A.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34976cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWordFeature(line):\n",
    "    words = line.split()\n",
    "    wordFreq = {}\n",
    "\n",
    "    for w in words[1:]:\n",
    "        try:\n",
    "            wordFreq[w] += 1\n",
    "        except:\n",
    "            wordFreq[w] = 1\n",
    "    print(wordFreq)\n",
    "    return wordFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f4b85ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pretty': 1, 'bad': 1}\n",
      "{'good': 1, 'plot': 1}\n",
      "{'not': 1, 'good': 1}\n",
      "{'pretty': 1, 'scenery': 1}\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./review_train.txt\"\n",
    "fb = open(filepath, 'r')\n",
    "line = fb.readline()\n",
    "\n",
    "while line:\n",
    "    extractWordFeature(line)\n",
    "    line = fb.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ccd37",
   "metadata": {},
   "source": [
    "### Task 1A.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "382852b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 pretty bad\n",
      "\n",
      "1 good plot\n",
      "\n",
      "-1 not good\n",
      "\n",
      "1 pretty scenery\n",
      "{'pretty': 0, 'bad': 1, 'good': 2, 'plot': 3, 'not': 4, 'scenery': 5}\n",
      "-1 bad plot\n",
      "{'bad': 0, 'plot': 1}\n"
     ]
    }
   ],
   "source": [
    "def dict_extractor(filepath):\n",
    "    fb = open(filepath, 'r')\n",
    "    line = fb.readline()\n",
    "    rv_dict = {}\n",
    "    nfeas = 0\n",
    "    while line:\n",
    "        print(line)\n",
    "        words = line.split()\n",
    "        for w in words[1:]:\n",
    "            if w not in rv_dict:\n",
    "                rv_dict[w] = nfeas\n",
    "                nfeas += 1\n",
    "        line = fb.readline()\n",
    "    fb.close()\n",
    "    return rv_dict\n",
    "\n",
    "\n",
    "print(dict_extractor(\"./review_train.txt\"))\n",
    "print(dict_extractor(\"./review_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "560d35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(filepath, fea_dict):\n",
    "    nfeas = len(fea_dict)\n",
    "    data = np.empty([0, nfeas])\n",
    "    target = np.empty([0, 1])\n",
    "    fb = open(filepath, 'r')\n",
    "    line = fb.readline()\n",
    "\n",
    "    while line:\n",
    "        tmp = np.zeros([1, nfeas])\n",
    "        words = line.split()\n",
    "        target = np.append(target, int(words[0]))\n",
    "        for w in words[1:]:\n",
    "            tmp[0, fea_dict[w]] += 1\n",
    "        data = np.append(data, tmp, axis=0)\n",
    "        line = fb.readline()\n",
    "\n",
    "    fb.close()\n",
    "    target = np.array(target).reshape(len(target), 1)\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ac53e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 1.]]),\n",
       " array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, ytrain = feature_extractor(r\"./review_train.txt\", dict_train)\n",
    "xtrain, ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "93ea28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(Z, Y):\n",
    "    return max(1 - Z*Y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0052e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: W = [[ 0. ]\n",
      " [-0.5]\n",
      " [ 0. ]\n",
      " [ 0.5]\n",
      " [-0.5]\n",
      " [ 0.5]], Loss = 1.25, Gradient = [-1. -0. -0. -0. -0. -1.]\n",
      "Epoch 1: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 1.0, Gradient = [-1. -0. -0. -0. -0. -1.]\n",
      "Epoch 2: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.6666666666666666, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 3: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.5, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 4: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.4, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 5: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.3333333333333333, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 6: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.2857142857142857, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 7: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.25, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 8: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.2222222222222222, Gradient = [0. 0. 0. 0. 0. 0.]\n",
      "Epoch 9: W = [[ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]], Loss = 0.2, Gradient = [0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "n_epoch = 10\n",
    "\n",
    "def gradientDescent(X, Y, alpha, n_epoch):\n",
    "    W = np.zeros((X.shape[1],1))\n",
    "    \n",
    "    LossSum = np.empty([0])\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for row in range(len(X)):\n",
    "            theta = W\n",
    "            Z = np.dot(X[row],W) # (1, 6) x (6, 1) --> (1,1)\n",
    "            \n",
    "            loss = hinge_loss(Z, Y[row])\n",
    "            LossSum = np.append(LossSum, loss)\n",
    "\n",
    "\n",
    "            gradient = np.where((1-(Z*Y[row]))> 0, (-X[row])*Y[row], 0)\n",
    "            W = theta - (alpha * gradient).reshape(len(gradient),1)\n",
    "\n",
    "\n",
    "        Loss = np.mean(LossSum)\n",
    "        print(\"Epoch {}: W = {}, Loss = {}, Gradient = {}\".format(epoch, W, Loss, gradient))\n",
    "    \n",
    "    return W\n",
    "\n",
    "W = gradientDescent(xtrain, ytrain, alpha, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aedebfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bad': 1, 'plot': 1}\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./review_test.txt\"\n",
    "fb = open(filepath, 'r')\n",
    "line = fb.readline()\n",
    "\n",
    "while line:\n",
    "    extractWordFeature(line)\n",
    "    line = fb.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c007be18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestX = np.asarray([[1., 1., 0., 0., 0., 0.]])\n",
    "def predict(W, TestX):\n",
    "    return np.dot(TestX, W)\n",
    "\n",
    "predict(W, TestX).flatten()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f1842",
   "metadata": {},
   "source": [
    "### Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8495d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100,))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "data = iris.data[:100,:]\n",
    "\n",
    "target = iris.target[:100]\n",
    "target[target==0] = -1\n",
    "\n",
    "data.shape , target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7f50b2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 98, 51, 62, 14, 52,  2, 86, 42, 49, 11, 95,  3, 94, 25, 74,  7,\n",
       "       75, 55, 13, 96,  0, 90, 53, 45, 69, 67, 84, 71, 43, 17, 87, 29, 21,\n",
       "       70, 46, 76, 85, 73, 35, 38, 31, 58,  5, 66, 19, 10, 34, 48, 40, 36,\n",
       "       20, 47, 88, 44, 16,  8,  4, 30, 56, 59, 72, 28, 65, 63, 78, 27, 37,\n",
       "       77,  6,  9, 99, 41, 23, 18, 80,  1, 54, 89, 83, 93, 97, 33, 81, 68,\n",
       "       12, 15, 60, 57, 32, 82, 61, 91, 26, 92, 22, 39, 79, 24, 50])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShuffledIndex = np.arange(0,100)\n",
    "np.random.shuffle(ShuffledIndex)\n",
    "ShuffledIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "96d95e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1, -1,  1, -1,  1, -1, -1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1,  1, -1,  1, -1,  1,  1, -1,  1,  1,  1,  1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1, -1, -1,\n",
       "        1, -1, -1,  1, -1, -1, -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "       -1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1,  1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[ShuffledIndex]\n",
    "Y = target[ShuffledIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5e39a082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 4), (80, 1), (20, 4), (20, 1))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = X[:80,:]\n",
    "Ytrain = Y[:80].reshape((-1,1))\n",
    "\n",
    "Xtest = X[80:,:]\n",
    "Ytest = Y[80:].reshape((-1,1))\n",
    "\n",
    "\n",
    "Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f2c2941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "n_epoch = 300\n",
    "num_features = Xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "38150cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeWeights():\n",
    "    return np.zeros((num_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "67431178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(Z, Y):\n",
    "    return max(1 - Z*Y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8cbb92fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.411025, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 1: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.2055125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 2: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.13700833333333332, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 3: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.10275625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 4: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.082205, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 5: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.06850416666666666, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 6: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.05871785714285714, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 7: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.051378125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 8: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.04566944444444444, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 9: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0411025, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 10: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.03736590909090909, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 11: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.03425208333333333, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 12: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.03161730769230769, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 13: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.02935892857142857, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 14: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.027401666666666664, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 15: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0256890625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 16: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.024177941176470586, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 17: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.02283472222222222, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 18: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.021632894736842104, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 19: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.02055125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 20: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.019572619047619047, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 21: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.018682954545454544, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 22: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.01787065217391304, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 23: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.017126041666666664, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 24: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.016440999999999997, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 25: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.015808653846153844, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 26: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.015223148148148147, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 27: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.014679464285714285, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 28: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.014173275862068964, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 29: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.013700833333333332, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 30: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.013258870967741934, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 31: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.01284453125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 32: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.01245530303030303, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 33: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.012088970588235293, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 34: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.011743571428571428, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 35: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.01141736111111111, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 36: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.011108783783783783, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 37: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.010816447368421052, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 38: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.010539102564102563, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 39: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.010275625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 40: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.010025, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 41: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.009786309523809524, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 42: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.009558720930232557, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 43: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.009341477272727272, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 44: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.009133888888888888, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 45: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00893532608695652, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 46: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.008745212765957446, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 47: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.008563020833333332, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 48: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00838826530612245, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 49: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.008220499999999999, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 50: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.008059313725490196, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 51: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.007904326923076922, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 52: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.007755188679245283, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 53: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0076115740740740736, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 54: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.007473181818181818, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 55: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.007339732142857143, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 56: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.007210964912280701, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 57: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.007086637931034482, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 58: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006966525423728813, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 59: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006850416666666666, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 60: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00673811475409836, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 61: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006629435483870967, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 62: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006524206349206349, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 63: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006422265625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 64: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006323461538461538, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 65: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006227651515151515, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 66: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.006134701492537313, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 67: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0060444852941176465, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 68: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005956884057971014, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 69: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005871785714285714, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 70: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0057890845070422536, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 71: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005708680555555555, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 72: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0056304794520547945, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 73: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005554391891891892, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 74: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005480333333333333, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 75: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005408223684210526, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 76: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005337987012987012, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 77: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0052695512820512816, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 78: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0052028481012658225, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 79: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0051378125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 80: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.005074382716049383, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 81: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0050125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 82: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00495210843373494, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 83: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004893154761904762, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 84: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0048355882352941176, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 85: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004779360465116279, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 86: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004724425287356322, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 87: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004670738636363636, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 88: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004618258426966292, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 89: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004566944444444444, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 90: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004516758241758241, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 91: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00446766304347826, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 92: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004419623655913979, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 93: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004372606382978723, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 94: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004326578947368421, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 95: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004281510416666666, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 96: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004237371134020619, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 97: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004194132653061225, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 98: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004151767676767676, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 99: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004110249999999999, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 100: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0040695544554455445, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 101: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.004029656862745098, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 102: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003990533980582524, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 103: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003952163461538461, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 104: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00391452380952381, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 105: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0038775943396226415, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 106: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0038413551401869158, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 107: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0038057870370370368, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 108: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0037708715596330273, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 109: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003736590909090909, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 110: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0037029279279279276, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 111: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0036698660714285713, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 112: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003637389380530973, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 113: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0036054824561403504, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 114: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0035741304347826084, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 115: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003543318965517241, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 116: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003513034188034188, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 117: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0034832627118644064, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 118: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003453991596638655, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 119: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003425208333333333, Gradient = [0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0033969008264462808, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 121: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00336905737704918, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 122: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0033416666666666664, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 123: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0033147177419354835, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 124: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0032882, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 125: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0032621031746031745, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 126: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0032364173228346454, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 127: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0032111328125, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 128: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003186240310077519, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 129: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003161730769230769, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 130: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003137595419847328, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 131: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0031138257575757575, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 132: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.003090413533834586, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 133: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0030673507462686566, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 134: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0030446296296296293, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 135: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0030222426470588233, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 136: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0030001824817518247, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 137: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002978442028985507, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 138: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0029570143884892082, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 139: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002935892857142857, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 140: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0029150709219858155, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 141: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0028945422535211268, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 142: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002874300699300699, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 143: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0028543402777777777, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 144: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002834655172413793, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 145: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0028152397260273973, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 146: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0027960884353741495, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 147: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002777195945945946, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 148: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0027585570469798658, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 149: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0027401666666666664, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 150: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002722019867549669, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 151: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002704111842105263, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 152: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0026864379084967317, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 153: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002668993506493506, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 154: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002651774193548387, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 155: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0026347756410256408, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 156: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0026179936305732484, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 157: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0026014240506329112, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 158: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002585062893081761, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 159: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00256890625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 160: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002552950310559006, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 161: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0025371913580246913, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 162: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0025216257668711655, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 163: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00250625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 164: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002491060606060606, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 165: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00247605421686747, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 166: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0024612275449101793, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 167: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002446577380952381, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 168: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002432100591715976, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 169: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0024177941176470588, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 170: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0024036549707602338, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 171: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0023896802325581393, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 172: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0023758670520231213, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 173: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002362212643678161, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 174: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0023487142857142856, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 175: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002335369318181818, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 176: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0023221751412429376, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 177: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002309129213483146, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 178: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0022962290502793296, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 179: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002283472222222222, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 180: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00227085635359116, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 181: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0022583791208791205, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 182: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00224603825136612, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 183: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00223383152173913, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 184: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0022217567567567567, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 185: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0022098118279569893, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 186: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002197994652406417, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 187: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0021863031914893614, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 188: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0021747354497354495, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 189: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0021632894736842104, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 190: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0021519633507853402, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 191: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002140755208333333, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 192: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002129663212435233, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 193: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0021186855670103093, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 194: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002107820512820513, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 195: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020970663265306123, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 196: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020864213197969543, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 197: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002075883838383838, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 198: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020654522613065326, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 199: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020551249999999997, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 200: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020449004975124376, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 201: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020347772277227723, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 202: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0020247536945812807, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 203: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002014828431372549, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 204: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.002005, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 205: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001995266990291262, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 206: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019856280193236713, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 207: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019760817307692305, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 208: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001966626794258373, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 209: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001957261904761905, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 210: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019479857819905211, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 211: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019387971698113207, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 212: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001929694835680751, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 213: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019206775700934579, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 214: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019117441860465115, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 215: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0019028935185185184, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 216: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018941244239631335, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 217: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018854357798165136, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 218: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018768264840182648, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 219: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018682954545454545, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 220: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018598416289592758, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 221: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018514639639639638, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 222: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018431614349775783, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 223: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018349330357142857, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 224: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018267777777777776, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 225: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018186946902654865, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 226: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00181068281938326, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 227: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0018027412280701752, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 228: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017948689956331877, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 229: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017870652173913042, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 230: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017793290043290042, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 231: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017716594827586205, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 232: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017640557939914163, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 233: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001756517094017094, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 234: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017490425531914893, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 235: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017416313559322032, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 236: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001734282700421941, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 237: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017269957983193276, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 238: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017197698744769872, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 239: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017126041666666665, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 240: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0017054979253112031, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 241: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016984504132231404, Gradient = [0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016914609053497941, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 243: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00168452868852459, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 244: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016776530612244898, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 245: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016708333333333332, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 246: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016640688259109311, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 247: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016573588709677418, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 248: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016507028112449798, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 249: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016441, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 250: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016375498007968126, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 251: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016310515873015873, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 252: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016246047430830037, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 253: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016182086614173227, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 254: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0016118627450980392, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 255: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.00160556640625, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 256: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015993190661478598, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 257: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015931201550387596, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 258: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015869691119691119, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 259: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015808653846153846, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 260: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015748084291187737, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 261: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001568797709923664, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 262: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015628326996197717, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 263: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015569128787878788, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 264: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015510377358490565, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 265: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001545206766917293, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 266: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015394194756554306, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 267: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015336753731343283, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 268: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015279739776951672, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 269: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015223148148148147, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 270: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015166974169741696, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 271: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015111213235294116, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 272: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015055860805860805, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 273: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0015000912408759124, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 274: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014946363636363636, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 275: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014892210144927536, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 276: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014838447653429602, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 277: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014785071942446041, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 278: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014732078853046595, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 279: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014679464285714285, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 280: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014627224199288255, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 281: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014575354609929077, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 282: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014523851590106005, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 283: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014472711267605634, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 284: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014421929824561402, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 285: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014371503496503496, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 286: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001432142857142857, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 287: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014271701388888888, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 288: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014222318339100345, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 289: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014173275862068965, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 290: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014124570446735394, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 291: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0014076198630136986, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 292: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001402815699658703, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 293: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0013980442176870747, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 294: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0013933050847457626, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 295: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.001388597972972973, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 296: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0013839225589225587, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 297: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0013792785234899329, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 298: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0013746655518394647, Gradient = [0. 0. 0. 0.]\n",
      "Epoch 299: W = [[-0.3 ]\n",
      " [-0.9 ]\n",
      " [ 1.44]\n",
      " [ 0.64]], Loss = 0.0013700833333333332, Gradient = [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def gradientDescent(X, Y, alpha, n_epoch):\n",
    "    \n",
    "    W = initializeWeights()\n",
    "    LossSum = np.empty([0])\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for row in range(len(X)):\n",
    "            theta = W\n",
    "            Z = np.dot(X[row],W) # (1, 4) x (4, 1) --> (1,1)\n",
    "            loss = hinge_loss(Z, Y[row])\n",
    "            LossSum = np.append(LossSum, loss)\n",
    "\n",
    "\n",
    "            gradient = np.where((1-(Z*Y[row]))> 0, (-X[row])*Y[row], 0)\n",
    "            W = theta - (alpha * gradient).reshape(len(gradient),1)\n",
    "\n",
    "\n",
    "        Loss = np.mean(LossSum)\n",
    "        print(\"Epoch {}: W = {}, Loss = {}, Gradient = {}\".format(epoch, W, Loss, gradient))\n",
    "    \n",
    "    return W\n",
    "\n",
    "W = gradientDescent(Xtrain, Ytrain, alpha, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e99f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, TestX):\n",
    "    return np.dot(TestX, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "73297613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.822],\n",
       "       [ 2.554],\n",
       "       [-3.286],\n",
       "       [ 2.158],\n",
       "       [ 3.6  ],\n",
       "       [-2.06 ],\n",
       "       [-3.254],\n",
       "       [ 2.38 ],\n",
       "       [ 1.762],\n",
       "       [-3.026],\n",
       "       [ 2.214],\n",
       "       [ 2.538],\n",
       "       [ 2.99 ],\n",
       "       [-2.   ],\n",
       "       [ 2.448],\n",
       "       [-3.052],\n",
       "       [-2.302],\n",
       "       [ 1.63 ],\n",
       "       [-1.636],\n",
       "       [ 2.684]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(W, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ce214756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.where(np.sign(predict(W, Xtest)) == Ytest, 1, 0).flatten())*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
