{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341b402e",
   "metadata": {},
   "source": [
    "# FP-Growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326df764",
   "metadata": {},
   "source": [
    "The FP-growth algorithm is described in the paper Han et al., Mining frequent patterns without candidate generation, where “FP” stands for frequent pattern. Given a dataset of transactions, the first step of FP-growth is to calculate item frequencies and identify frequent items. Different from Apriori-like algorithms designed for the same purpose, the second step of FP-growth uses a suffix tree (FP-tree) structure to encode transactions without generating candidate sets explicitly, which are usually expensive to generate. After the second step, the frequent itemsets can be extracted from the FP-tree. In spark.mllib, we implemented a parallel version of FP-growth called PFP, as described in Li et al., PFP: Parallel FP-growth for query recommendation. PFP distributes the work of growing FP-trees based on the suffixes of transactions, and hence is more scalable than a single-machine implementation. We refer users to the papers for more details.\n",
    "\n",
    "`spark.ml`’s FP-growth implementation takes the following (hyper-)parameters:\n",
    "\n",
    "- `minSupport`: the minimum support for an itemset to be identified as frequent. For example, if an item appears 3 out of 5 transactions, it has a support of 3/5=0.6.\n",
    "\n",
    "- `minConfidence`: minimum confidence for generating Association Rule. Confidence is an indication of how often an association rule has been found to be true. For example, if in the transactions itemset X appears 4 times, X and Y co-occur only 2 times, the confidence for the rule X => Y is then 2/4 = 0.5. The parameter will not affect the mining for frequent itemsets, but specify the minimum confidence for generating association rules from frequent itemsets.\n",
    "\n",
    "- `numPartitions`: the number of partitions used to distribute the work. By default the param is not set, and number of partitions of the input dataset is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb21012",
   "metadata": {},
   "source": [
    "The `FPGrowthModel` provides:\n",
    "\n",
    "- `freqItemsets`: frequent itemsets in the format of DataFrame(“items”[Array], “freq”[Long])\n",
    "- `associationRules`: association rules generated with confidence above minConfidence, in the format of DataFrame(“antecedent”[Array], “consequent”[Array], “confidence”[Double]).\n",
    "- `transform`: For each transaction in itemsCol, the transform method will compare its items against the antecedents of each association rule. If the record contains all the antecedents of a specific association rule, the rule will be considered as applicable and its consequents will be added to the prediction result. The transform method will summarize the consequents from all the applicable rules as prediction. The prediction column has the same data type as itemsCol and does not contain existing items in the itemsCol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0410a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"FP-Growth\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6acde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (0, [1, 2, 5]),\n",
    "    (1, [1, 2, 3, 5]),\n",
    "    (2, [1, 2])\n",
    "], [\"id\", \"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c5db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fpGrowth.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b200fc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|    items|freq|\n",
      "+---------+----+\n",
      "|      [5]|   2|\n",
      "|   [5, 2]|   2|\n",
      "|[5, 2, 1]|   2|\n",
      "|   [5, 1]|   2|\n",
      "|      [2]|   3|\n",
      "|   [2, 1]|   3|\n",
      "|      [1]|   3|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display frequent itemsets.\n",
    "model.freqItemsets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b1c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----+------------------+\n",
      "|antecedent|consequent|        confidence|lift|           support|\n",
      "+----------+----------+------------------+----+------------------+\n",
      "|    [5, 2]|       [1]|               1.0| 1.0|0.6666666666666666|\n",
      "|    [5, 1]|       [2]|               1.0| 1.0|0.6666666666666666|\n",
      "|       [5]|       [2]|               1.0| 1.0|0.6666666666666666|\n",
      "|       [5]|       [1]|               1.0| 1.0|0.6666666666666666|\n",
      "|       [2]|       [5]|0.6666666666666666| 1.0|0.6666666666666666|\n",
      "|       [2]|       [1]|               1.0| 1.0|               1.0|\n",
      "|       [1]|       [5]|0.6666666666666666| 1.0|0.6666666666666666|\n",
      "|       [1]|       [2]|               1.0| 1.0|               1.0|\n",
      "|    [2, 1]|       [5]|0.6666666666666666| 1.0|0.6666666666666666|\n",
      "+----------+----------+------------------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display generated association rules.\n",
    "model.associationRules.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30aa10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+\n",
      "| id|       items|prediction|\n",
      "+---+------------+----------+\n",
      "|  0|   [1, 2, 5]|        []|\n",
      "|  1|[1, 2, 3, 5]|        []|\n",
      "|  2|      [1, 2]|       [5]|\n",
      "+---+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform examines the input items against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2454924",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1b66d",
   "metadata": {},
   "source": [
    "## Example Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405503dc",
   "metadata": {},
   "source": [
    "Next, you can play with the given dataset `example_dataset.csv`, it will be downloaded into the current directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d1472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-20 20:21:27--  https://raw.githubusercontent.com/tnurbek/ds702/main/Lab14/products.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 494162 (483K) [text/plain]\n",
      "Saving to: ‘example_dataset.csv’\n",
      "\n",
      "example_dataset.csv 100%[===================>] 482.58K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-04-20 20:21:28 (20.7 MB/s) - ‘example_dataset.csv’ saved [494162/494162]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O example_dataset.csv 'https://raw.githubusercontent.com/tnurbek/ds702/main/Lab14/products.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196798a",
   "metadata": {},
   "source": [
    "Create session/context..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7032eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"FP-Growth\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b5ae6",
   "metadata": {},
   "source": [
    "Use this function (`getFromFile()`) in order to read your dataset as needed, appending all items into a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676ce637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def getFromFile(filename):\n",
    "    itemSetList = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for line in csv_reader:\n",
    "            line = list(filter(None, line))\n",
    "            itemSetList.append(line)\n",
    "\n",
    "    return itemSetList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "725a23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemSetList = getFromFile('example_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6091a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Lassi', 'Coffee Powder', 'Butter', 'Yougurt', 'Ghee', 'Cheese'],\n",
       " ['Ghee', 'Coffee Powder'],\n",
       " ['Lassi', 'Tea Powder', 'Butter', 'Cheese'],\n",
       " ['Cheese', 'Tea Powder', 'Panner', 'Coffee Powder', 'Butter', 'Bread'],\n",
       " ['Cheese', 'Yougurt', 'Coffee Powder', 'Sugar', 'Butter', 'Sweet']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemSetList[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd6e91",
   "metadata": {},
   "source": [
    "Make your dataframe look like: \n",
    "``` \n",
    "[\n",
    "    (0, [1, 2, 5]),\n",
    "    (1, [1, 2, 3, 5]),\n",
    "    (2, [1, 2])\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "880f1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "lst = list(map(lambda x, y: (x, y), range(len(itemSetList)), itemSetList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb89addf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ['Lassi', 'Coffee Powder', 'Butter', 'Yougurt', 'Ghee', 'Cheese']),\n",
       " (1, ['Ghee', 'Coffee Powder']),\n",
       " (2, ['Lassi', 'Tea Powder', 'Butter', 'Cheese']),\n",
       " (3, ['Cheese', 'Tea Powder', 'Panner', 'Coffee Powder', 'Butter', 'Bread']),\n",
       " (4, ['Cheese', 'Yougurt', 'Coffee Powder', 'Sugar', 'Butter', 'Sweet'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd76266",
   "metadata": {},
   "source": [
    "Create dataframe called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c5c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "df = spark.createDataFrame(lst, [\"id\", \"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30630c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0, items=['Lassi', 'Coffee Powder', 'Butter', 'Yougurt', 'Ghee', 'Cheese']),\n",
       " Row(id=1, items=['Ghee', 'Coffee Powder']),\n",
       " Row(id=2, items=['Lassi', 'Tea Powder', 'Butter', 'Cheese']),\n",
       " Row(id=3, items=['Cheese', 'Tea Powder', 'Panner', 'Coffee Powder', 'Butter', 'Bread']),\n",
       " Row(id=4, items=['Cheese', 'Yougurt', 'Coffee Powder', 'Sugar', 'Butter', 'Sweet'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66803f4d",
   "metadata": {},
   "source": [
    "Next, try to do the same approach as above, create a `FPGrowth` model, and find frequent itemsets, you may use different hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22b02be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.2, minConfidence=0.15)\n",
    "model = fpGrowth.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "203ea16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12526"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "022c0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               items|freq|\n",
      "+--------------------+----+\n",
      "|            [Cheese]|5476|\n",
      "|[Cheese, Coffee P...|2517|\n",
      "|     [Cheese, Bread]|2530|\n",
      "|   [Cheese, Yougurt]|2532|\n",
      "|        [Tea Powder]|5383|\n",
      "|     [Coffee Powder]|5509|\n",
      "|[Coffee Powder, G...|2578|\n",
      "|[Coffee Powder, M...|2518|\n",
      "|             [Sweet]|5483|\n",
      "|      [Sweet, Bread]|2539|\n",
      "|       [Sweet, Milk]|2512|\n",
      "|             [Bread]|5484|\n",
      "|[Bread, Coffee Po...|2528|\n",
      "|    [Bread, Yougurt]|2507|\n",
      "|       [Bread, Milk]|2517|\n",
      "|            [Butter]|5481|\n",
      "|     [Butter, Sweet]|2543|\n",
      "|      [Butter, Ghee]|2530|\n",
      "|   [Butter, Yougurt]|2529|\n",
      "|     [Butter, Sugar]|2571|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.freqItemsets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9e382c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-------------------+------------------+-------------------+\n",
      "|     antecedent|     consequent|         confidence|              lift|            support|\n",
      "+---------------+---------------+-------------------+------------------+-------------------+\n",
      "|      [Yougurt]|       [Cheese]|0.46011266581864435| 1.052478314836439|  0.202139549736548|\n",
      "|      [Yougurt]|        [Bread]| 0.4555696892604034|1.0405663617206078|0.20014370110170845|\n",
      "|      [Yougurt]|       [Butter]|0.45956750863165546|1.0502723249626194|0.20190004790036722|\n",
      "|      [Yougurt]|[Coffee Powder]|0.46429220425222606|1.0556769196702456|0.20397573048060036|\n",
      "|      [Yougurt]|         [Milk]|0.45666000363438125|1.0351290636127868|0.20062270477406993|\n",
      "|      [Yougurt]|        [Sugar]|0.45956750863165546|1.0500807393506233|0.20190004790036722|\n",
      "|       [Cheese]|[Coffee Powder]| 0.4596420745069394|1.0451037620754988|0.20094204055564427|\n",
      "|       [Cheese]|        [Bread]| 0.4620160701241782|1.0552905350794048|0.20197988184576082|\n",
      "|       [Cheese]|      [Yougurt]|0.46238130021913804|1.0524783148364387|  0.202139549736548|\n",
      "|       [Butter]|        [Sweet]|0.46396642948367084|1.0599386277060843|0.20301772313587738|\n",
      "|       [Butter]|         [Ghee]|0.46159459952563403| 1.049352804656641|0.20197988184576082|\n",
      "|       [Butter]|      [Yougurt]| 0.4614121510673235|1.0502723249626191|0.20190004790036722|\n",
      "|       [Butter]|        [Sugar]| 0.4690749863163656| 1.071804684166143|0.20525307360689765|\n",
      "|         [Ghee]|[Coffee Powder]|0.46787658802177856|1.0638268545218366|0.20581191122465273|\n",
      "|         [Ghee]|       [Butter]| 0.4591651542649728| 1.049352804656641|0.20197988184576082|\n",
      "|         [Ghee]|        [Lassi]| 0.4557168784029038|1.0508670137840157|0.20046303688328276|\n",
      "|         [Ghee]|         [Milk]| 0.4557168784029038| 1.032991244819901|0.20046303688328276|\n",
      "|         [Ghee]|       [Panner]|0.45789473684210524|1.0535616226458873|0.20142104422800575|\n",
      "|         [Ghee]|        [Sugar]|0.45662431941923776|1.0433557506467297|0.20086220661025067|\n",
      "|[Coffee Powder]|       [Cheese]|  0.456888727536758|1.0451037620754988|0.20094204055564427|\n",
      "+---------------+---------------+-------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.associationRules.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6965df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------+--------------------------------------------------+\n",
      "| id|                                             items|                                        prediction|\n",
      "+---+--------------------------------------------------+--------------------------------------------------+\n",
      "|  0|[Lassi, Coffee Powder, Butter, Yougurt, Ghee, C...|               [Bread, Milk, Sugar, Sweet, Panner]|\n",
      "|  1|                             [Ghee, Coffee Powder]|[Butter, Lassi, Milk, Panner, Sugar, Cheese, Br...|\n",
      "|  2|               [Lassi, Tea Powder, Butter, Cheese]|[Coffee Powder, Bread, Yougurt, Sweet, Ghee, Su...|\n",
      "|  3|[Cheese, Tea Powder, Panner, Coffee Powder, But...|        [Yougurt, Sweet, Ghee, Sugar, Milk, Lassi]|\n",
      "|  4|[Cheese, Yougurt, Coffee Powder, Sugar, Butter,...|                        [Bread, Milk, Ghee, Lassi]|\n",
      "|  5|    [Sugar, Tea Powder, Ghee, Sweet, Panner, Milk]|    [Coffee Powder, Butter, Lassi, Bread, Yougurt]|\n",
      "|  6|                            [Sweet, Coffee Powder]|[Cheese, Ghee, Milk, Bread, Lassi, Yougurt, But...|\n",
      "|  7|                            [Butter, Ghee, Panner]|[Sweet, Yougurt, Sugar, Coffee Powder, Lassi, M...|\n",
      "|  8|[Sweet, Tea Powder, Butter, Yougurt, Sugar, Che...|         [Bread, Coffee Powder, Milk, Ghee, Lassi]|\n",
      "|  9|                                    [Panner, Ghee]|[Coffee Powder, Butter, Lassi, Milk, Sugar, Bread]|\n",
      "| 10|          [Milk, Panner, Tea Powder, Sweet, Bread]|[Coffee Powder, Lassi, Ghee, Yougurt, Sugar, Bu...|\n",
      "| 11|[Ghee, Coffee Powder, Milk, Yougurt, Lassi, Sug...|                            [Cheese, Bread, Sweet]|\n",
      "| 12|[Butter, Coffee Powder, Panner, Sweet, Ghee, La...|             [Yougurt, Sugar, Milk, Cheese, Bread]|\n",
      "| 13|[Bread, Lassi, Coffee Powder, Tea Powder, Sweet...|                   [Butter, Milk, Cheese, Yougurt]|\n",
      "| 14|       [Milk, Sweet, Butter, Sugar, Lassi, Panner]|             [Ghee, Yougurt, Coffee Powder, Bread]|\n",
      "| 15|                [Bread, Coffee Powder, Tea Powder]|[Cheese, Ghee, Milk, Lassi, Yougurt, Sweet, Pan...|\n",
      "| 16|                      [Butter, Ghee, Milk, Cheese]|[Coffee Powder, Bread, Yougurt, Sweet, Sugar, L...|\n",
      "| 17|                            [Bread, Coffee Powder]|[Cheese, Ghee, Milk, Lassi, Yougurt, Sweet, Pan...|\n",
      "| 18|[Cheese, Tea Powder, Sweet, Lassi, Coffee Powde...|              [Bread, Yougurt, Ghee, Milk, Butter]|\n",
      "| 19|[Panner, Lassi, Butter, Cheese, Yougurt, Tea Po...|        [Bread, Coffee Powder, Sugar, Sweet, Ghee]|\n",
      "+---+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(df).show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfbe50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d65b605b1ebac98c1535b24e77f9feff4a0d49b5155481ff8a814ffe3e13ad93"
  },
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
