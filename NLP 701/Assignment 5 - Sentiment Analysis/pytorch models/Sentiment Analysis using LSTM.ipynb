{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_csv = './data/IMDB Dataset.csv'\n",
    "df = pd.read_csv(base_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting to train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split data to train and test initially.Doing this on earlier stage allows to avoid data lekage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (37500,)\n",
      "shape of test data is (12500,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df['review'].values,df['sentiment'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def tockenize(x_train,y_train,x_val,y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of most common words\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_val:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_16112/442953369.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing review length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAV3UlEQVR4nO3df6zdd33f8edrTkmzlI6E0Cs3TuegGqaAWxeuklSw6paMYEJHYEIsUUQMZBhEIoFkqXPWamGwSOnWlI2IZjXDSpCyhKyB2gphwbgc0UkLxIEU5wdpboJRbJlYTQLZhSn00vf+OJ+bHpxr+/qcm3vv+fr5kI7O9/v+/jif973X9+Xvj3NuqgpJ0ontHy33ACRJy88wkCQZBpIkw0CShGEgSQJOWu4BDOuMM86otWvXDrXtj3/8Y0499dTFHdAK0uX+utwbdLu/LvcG49Pffffd97dV9YrD62MbBmvXrmXPnj1Dbdvr9ZiamlrcAa0gXe6vy71Bt/vrcm8wPv0l+f58dU8TSZIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJMX4H8ij2HvgR7936pSV/3X3XvW3JX1OSFsIjA0mSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkFhAGSbYnOZTkgYHa55Pc3x77ktzf6muT/L+BZf9tYJvXJ9mbZDrJp5Kk1U9PsivJo+35tBehT0nSUSzkyOAmYONgoar+dVVtqKoNwB3AFwYWPza3rKo+NFC/EfgAsK495va5FdhdVeuA3W1ekrSEjhkGVfV14On5lrX/3b8buPVo+0iyGvjlqrqnqgr4HPCOtvhi4OY2ffNAXZK0REb9ewb/HHiyqh4dqJ2d5NvAs8AfVtVfAWcC+wfW2d9qABNVdbBN/wCYONKLJdkMbAaYmJig1+sNNeiJU2DL+tmhth3FsOM9XjMzM0v2Wkuty71Bt/vrcm8w/v2NGgaX8vNHBQeBX6uqp5K8HviLJK9Z6M6qqpLUUZZvA7YBTE5O1tTU1FCDvuGWHVy/d+n/rs++y6aW5HV6vR7Dfm1Wui73Bt3ur8u9wfj3N/RvxCQnAf8KeP1craqeA55r0/cleQx4FXAAWDOw+ZpWA3gyyeqqOthOJx0adkySpOGMcmvpvwC+W1XPn/5J8ookq9r0K+lfKH68nQZ6Nsn57TrD5cCOttlOYFOb3jRQlyQtkYXcWnor8H+AVyfZn+SKtugSXnjh+HeA77RbTf8c+FBVzV18/jDw34Fp4DHgy61+HfDmJI/SD5jrhm9HkjSMY54mqqpLj1B/7zy1O+jfajrf+nuA185Tfwq44FjjkCS9eHwHsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEks7G8gb09yKMkDA7WPJTmQ5P72uGhg2dVJppM8kuQtA/WNrTadZOtA/ewk32j1zyd5yWI2KEk6toUcGdwEbJyn/smq2tAedwEkOQe4BHhN2+ZPk6xKsgr4NPBW4Bzg0rYuwB+1ff068AxwxSgNSZKO3zHDoKq+Djy9wP1dDNxWVc9V1feAaeDc9piuqser6qfAbcDFSQK8Cfjztv3NwDuOrwVJ0qhOGmHbq5JcDuwBtlTVM8CZwD0D6+xvNYAnDqufB7wc+GFVzc6z/gsk2QxsBpiYmKDX6w018IlTYMv62WOvuMiGHe/xmpmZWbLXWmpd7g263V+Xe4Px72/YMLgR+ARQ7fl64P2LNagjqaptwDaAycnJmpqaGmo/N9yyg+v3jpKDw9l32dSSvE6v12PYr81K1+XeoNv9dbk3GP/+hvqNWFVPzk0n+QxwZ5s9AJw1sOqaVuMI9aeAlyU5qR0dDK4vSVoiQ91ammT1wOw7gbk7jXYClyQ5OcnZwDrgm8C9wLp259BL6F9k3llVBXwNeFfbfhOwY5gxSZKGd8wjgyS3AlPAGUn2A9cAU0k20D9NtA/4IEBVPZjkduAhYBa4sqp+1vZzFXA3sArYXlUPtpf4t8BtSf4j8G3gs4vVnCRpYY4ZBlV16TzlI/7CrqprgWvnqd8F3DVP/XH6dxtJkpaJ70CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiYX9DeTtwO8Bh6rqta32n4F/CfwUeAx4X1X9MMla4GHgkbb5PVX1obbN64GbgFPo//nLj1RVJTkd+Dywlv7fU353VT2zSP2tKGu3fmlJXmfL+lnee9hr7bvubUvy2pLG00KODG4CNh5W2wW8tqp+A/gb4OqBZY9V1Yb2+NBA/UbgA8C69pjb51Zgd1WtA3a3eUnSEjpmGFTV14GnD6t9papm2+w9wJqj7SPJauCXq+qeqirgc8A72uKLgZvb9M0DdUnSEjnmaaIFeD/90zxzzk7ybeBZ4A+r6q+AM4H9A+vsbzWAiao62KZ/AEwc6YWSbAY2A0xMTNDr9YYa8MQp/VMpXTVff8N+rVaamZmZzvQyny731+XeYPz7GykMkvwBMAvc0koHgV+rqqfaNYK/SPKahe6vXUOooyzfBmwDmJycrKmpqaHGfcMtO7h+72Lk4Mq0Zf3sC/rbd9nU8gxmkfV6PYb9vo+DLvfX5d5g/Psb+jdikvfSv7B8QTv1Q1U9BzzXpu9L8hjwKuAAP38qaU2rATyZZHVVHWynkw4NOyZJ0nCGurU0yUbg94G3V9VPBuqvSLKqTb+S/oXix9tpoGeTnJ8kwOXAjrbZTmBTm940UJckLZGF3Fp6KzAFnJFkP3AN/buHTgZ29X+3P38L6e8AH0/yd8DfAx+qqrmLzx/mH24t/XJ7AFwH3J7kCuD7wLsXpTNJ0oIdMwyq6tJ5yp89wrp3AHccYdke4LXz1J8CLjjWOCRJLx7fgSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSCwyDJNuTHErywEDt9CS7kjzank9r9ST5VJLpJN9J8rqBbTa19R9Nsmmg/voke9s2n0r7w8qSpKWx0CODm4CNh9W2Arurah2wu80DvBVY1x6bgRuhHx7ANcB5wLnANXMB0tb5wMB2h7+WJOlFtKAwqKqvA08fVr4YuLlN3wy8Y6D+ueq7B3hZktXAW4BdVfV0VT0D7AI2tmW/XFX3VFUBnxvYlyRpCYxyzWCiqg626R8AE236TOCJgfX2t9rR6vvnqUuSlshJi7GTqqoktRj7Opokm+mfemJiYoJerzfUfiZOgS3rZxdxZCvLfP0N+7VaaWZmZjrTy3y63F+Xe4Px72+UMHgyyeqqOthO9Rxq9QPAWQPrrWm1A8DUYfVeq6+ZZ/0XqKptwDaAycnJmpqamm+1Y7rhlh1cv3dRcnBF2rJ+9gX97btsankGs8h6vR7Dft/HQZf763JvMP79jXKaaCcwd0fQJmDHQP3ydlfR+cCP2umku4ELk5zWLhxfCNzdlj2b5Px2F9HlA/uSJC2BBf33OMmt9P9Xf0aS/fTvCroOuD3JFcD3gXe31e8CLgKmgZ8A7wOoqqeTfAK4t6338aqauyj9Yfp3LJ0CfLk9JElLZEFhUFWXHmHRBfOsW8CVR9jPdmD7PPU9wGsXMhZJ0uLzHciSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkhghDJK8Osn9A49nk3w0yceSHBioXzSwzdVJppM8kuQtA/WNrTadZOuoTUmSjs9Jw25YVY8AGwCSrAIOAF8E3gd8sqr+eHD9JOcAlwCvAX4V+GqSV7XFnwbeDOwH7k2ys6oeGnZskqTjM3QYHOYC4LGq+n6SI61zMXBbVT0HfC/JNHBuWzZdVY8DJLmtrWsYSNISWawwuAS4dWD+qiSXA3uALVX1DHAmcM/AOvtbDeCJw+rnzfciSTYDmwEmJibo9XpDDXbiFNiyfnaobcfBfP0N+7VaaWZmZjrTy3y63F+Xe4Px72/kMEjyEuDtwNWtdCPwCaDa8/XA+0d9HYCq2gZsA5icnKypqamh9nPDLTu4fu9i5eDKs2X97Av623fZ1PIMZpH1ej2G/b6Pgy731+XeYPz7W4zfiG8FvlVVTwLMPQMk+QxwZ5s9AJw1sN2aVuModUnSEliMW0svZeAUUZLVA8veCTzQpncClyQ5OcnZwDrgm8C9wLokZ7ejjEvaupKkJTLSkUGSU+nfBfTBgfJ/SrKB/mmifXPLqurBJLfTvzA8C1xZVT9r+7kKuBtYBWyvqgdHGZck6fiMFAZV9WPg5YfV3nOU9a8Frp2nfhdw1yhjkSQNz3cgS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksQihEGSfUn2Jrk/yZ5WOz3JriSPtufTWj1JPpVkOsl3krxuYD+b2vqPJtk06rgkSQu3WEcGv1tVG6pqss1vBXZX1Tpgd5sHeCuwrj02AzdCPzyAa4DzgHOBa+YCRJL04nuxThNdDNzcpm8G3jFQ/1z13QO8LMlq4C3Arqp6uqqeAXYBG1+ksUmSDnPSIuyjgK8kKeDPqmobMFFVB9vyHwATbfpM4ImBbfe32pHqPyfJZvpHFExMTNDr9YYa8MQpsGX97FDbjoP5+hv2a7XSzMzMdKaX+XS5vy73BuPf32KEwRur6kCSXwF2Jfnu4MKqqhYUI2tBsw1gcnKypqamhtrPDbfs4Pq9i9H6yrRl/ewL+tt32dTyDGaR9Xo9hv2+j4Mu99fl3mD8+xv5NFFVHWjPh4Av0j/n/2Q7/UN7PtRWPwCcNbD5mlY7Ul2StARGCoMkpyZ56dw0cCHwALATmLsjaBOwo03vBC5vdxWdD/yonU66G7gwyWntwvGFrSZJWgKjniuZAL6YZG5f/6Oq/leSe4Hbk1wBfB94d1v/LuAiYBr4CfA+gKp6OskngHvbeh+vqqdHHJskaYFGCoOqehz4zXnqTwEXzFMv4Moj7Gs7sH2U8UiShuM7kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxOJ8aqnGwNqtX1qW19133duW5XUlHR+PDCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJEcIgyVlJvpbkoSQPJvlIq38syYEk97fHRQPbXJ1kOskjSd4yUN/YatNJto7WkiTpeI3yDuRZYEtVfSvJS4H7kuxqyz5ZVX88uHKSc4BLgNcAvwp8Ncmr2uJPA28G9gP3JtlZVQ+NMDZJ0nEYOgyq6iBwsE3/3yQPA2ceZZOLgduq6jnge0mmgXPbsumqehwgyW1tXcNAkpbIonw2UZK1wG8B3wDeAFyV5HJgD/2jh2foB8U9A5vt5x/C44nD6ucd4XU2A5sBJiYm6PV6Q4134hTYsn52qG3HwUrqb9jv0ZHMzMws+j5Xki731+XeYPz7GzkMkvwScAfw0ap6NsmNwCeAas/XA+8f9XUAqmobsA1gcnKypqamhtrPDbfs4Pq93f2Mvi3rZ1dMf/sum1rU/fV6PYb9vo+DLvfX5d5g/Psb6TdGkl+gHwS3VNUXAKrqyYHlnwHubLMHgLMGNl/TahylLklaAqPcTRTgs8DDVfUnA/XVA6u9E3igTe8ELklycpKzgXXAN4F7gXVJzk7yEvoXmXcOOy5J0vEb5cjgDcB7gL1J7m+1fwdcmmQD/dNE+4APAlTVg0lup39heBa4sqp+BpDkKuBuYBWwvaoeHGFckqTjNMrdRP8byDyL7jrKNtcC185Tv+to20mSXly+A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCSxSB9UJx3J2q1fWtT9bVk/y3sXuM99171tUV9b6jKPDCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJ33SmDlvsN7wtlG920zjyyECSZBhIklZQGCTZmOSRJNNJti73eCTpRLIirhkkWQV8GngzsB+4N8nOqnpoeUcmHb9RrlUczwfxzcfrFRrWSjkyOBeYrqrHq+qnwG3Axcs8Jkk6YaSqlnsMJHkXsLGq/k2bfw9wXlVdddh6m4HNbfbVwCNDvuQZwN8Oue046HJ/Xe4Nut1fl3uD8envn1bVKw4vrojTRAtVVduAbaPuJ8meqppchCGtSF3ur8u9Qbf763JvMP79rZTTRAeAswbm17SaJGkJrJQwuBdYl+TsJC8BLgF2LvOYJOmEsSJOE1XVbJKrgLuBVcD2qnrwRXzJkU81rXBd7q/LvUG3++tybzDm/a2IC8iSpOW1Uk4TSZKWkWEgSTrxwmDcP/YiyfYkh5I8MFA7PcmuJI+259NaPUk+1Xr9TpLXLd/Ijy3JWUm+luShJA8m+Uird6W/X0zyzSR/3fr7D61+dpJvtD4+326iIMnJbX66LV+7rA0sQJJVSb6d5M4236Xe9iXZm+T+JHtarRM/m3CChcHAx168FTgHuDTJOcs7quN2E7DxsNpWYHdVrQN2t3no97muPTYDNy7RGIc1C2ypqnOA84Er2/enK/09B7ypqn4T2ABsTHI+8EfAJ6vq14FngCva+lcAz7T6J9t6K91HgIcH5rvUG8DvVtWGgfcTdOVnE6rqhHkAvw3cPTB/NXD1co9riD7WAg8MzD8CrG7Tq4FH2vSfAZfOt944PIAd9D+vqnP9Af8Y+BZwHv13rZ7U6s//jNK/u+632/RJbb0s99iP0tMa+r8Q3wTcCaQrvbVx7gPOOKzWmZ/NE+rIADgTeGJgfn+rjbuJqjrYpn8ATLTpse23nTb4LeAbdKi/dhrlfuAQsAt4DPhhVc22VQZ7eL6/tvxHwMuXdMDH578Avw/8fZt/Od3pDaCAryS5r300DnToZ3NFvM9Ai6eqKslY3y+c5JeAO4CPVtWzSZ5fNu79VdXPgA1JXgZ8EfhnyzuixZHk94BDVXVfkqllHs6L5Y1VdSDJrwC7knx3cOG4/2yeaEcGXf3YiyeTrAZoz4dafez6TfIL9IPglqr6Qit3pr85VfVD4Gv0T528LMncf8wGe3i+v7b8nwBPLe1IF+wNwNuT7KP/qcNvAv4r3egNgKo60J4P0Q/yc+nQz+aJFgZd/diLncCmNr2J/rn2ufrl7c6G84EfDRzSrjjpHwJ8Fni4qv5kYFFX+ntFOyIgySn0r4c8TD8U3tVWO7y/ub7fBfxltRPQK01VXV1Va6pqLf1/V39ZVZfRgd4Akpya5KVz08CFwAN05GcTOLEuILeftYuAv6F/rvYPlns8Q4z/VuAg8Hf0z0NeQf9c627gUeCrwOlt3dC/e+oxYC8wudzjP0Zvb6R/XvY7wP3tcVGH+vsN4NutvweAf9/qrwS+CUwD/xM4udV/sc1Pt+WvXO4eFtjnFHBnl3prffx1ezw497ujKz+bVeXHUUiSTrzTRJKkeRgGkiTDQJJkGEiSMAwkSRgGkiQMA0kS8P8B82saihekv80AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    37500.000000\n",
       "mean        69.223600\n",
       "std         48.227125\n",
       "min          0.000000\n",
       "25%         39.000000\n",
       "50%         54.000000\n",
       "75%         84.000000\n",
       "max        548.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_len = [len(i) for i in x_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations : <br>a) Mean review length = around 69.<br> b) minimum length of reviews is 2.<br>c)There are quite a few reviews that are extremely long, we can manually investigate them to check whether we need to include or exclude them from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will pad each of the sequence to max length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have very less number of reviews with length > 500.\n",
    "#So we will consideronly those below it.\n",
    "x_train_pad = padding_(x_train,500)\n",
    "x_test_pad = padding_(x_test,500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching and loading as tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 500])\n",
      "Sample input: \n",
      " tensor([[  0,   0,   0,  ...,  30,  23, 304],\n",
      "        [  0,   0,   0,  ..., 511, 308,  60],\n",
      "        [  0,   0,   0,  ..., 126,   6, 799],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,  35, 303, 525],\n",
      "        [  0,   0,   0,  ..., 307,  11, 619],\n",
      "        [  0,   0,   0,  ..., 148,  66,   2]], dtype=torch.int32)\n",
      "Sample input: \n",
      " tensor([1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add an embedding layer because there are less words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
    "        super(SentimentRNN,self).__init__()\n",
    " \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "        \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 1000]\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(1001, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.5234811951319377 val_loss : 0.3975106648206711\n",
      "train_accuracy : 74.38666666666667 val_accuracy : 82.344\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../working/state_dict.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16112/2073135160.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch_val_loss\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mvalid_loss_min\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../working/state_dict.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loss_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch_val_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mvalid_loss_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_val_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../working/state_dict.pt'"
     ]
    }
   ],
   "source": [
    "clip = 5\n",
    "epochs = 5 \n",
    "valid_loss_min = np.Inf\n",
    "# train for some number of epochs\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output,h = model(inputs,h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    " \n",
    "    \n",
    "        \n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in valid_loader:\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, val_h = model(inputs, val_h)\n",
    "            val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            accuracy = acc(output,labels)\n",
    "            val_acc += accuracy\n",
    "            \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(25*'==')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "        word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n",
    "                         if preprocess_string(word) in vocab.keys()])\n",
    "        word_seq = np.expand_dims(word_seq,axis=0)\n",
    "        pad =  torch.from_numpy(padding_(word_seq,500))\n",
    "        inputs = pad.to(device)\n",
    "        batch_size = 1\n",
    "        h = model.init_hidden(batch_size)\n",
    "        h = tuple([each.data for each in h])\n",
    "        output, h = model(inputs, h)\n",
    "        return(output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = 30\n",
    "print(df['review'][index])\n",
    "print('='*70)\n",
    "print(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\n",
    "print('='*70)\n",
    "pro = predict_text(df['review'][index])\n",
    "status = \"positive\" if pro > 0.5 else \"negative\"\n",
    "pro = (1 - pro) if status == \"negative\" else pro\n",
    "print(f'Predicted sentiment is {status} with a probability of {pro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = 32\n",
    "print(df['review'][index])\n",
    "print('='*70)\n",
    "print(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\n",
    "print('='*70)\n",
    "pro = predict_text(df['review'][index])\n",
    "status = \"positive\" if pro > 0.5 else \"negative\"\n",
    "pro = (1 - pro) if status == \"negative\" else pro\n",
    "print(f'predicted sentiment is {status} with a probability of {pro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvement suggestions are as follow:\n",
    "\n",
    "* Running a hyperparameter search to optimize your configurations.\n",
    "* Using pretraned word embeddings like Glove word embeddings\n",
    "* Increasing the model complexity like adding more layers/ using bidirectional LSTMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
