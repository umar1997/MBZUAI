{"cells":[{"cell_type":"markdown","metadata":{"id":"BafKS1rR6Mkc"},"source":["![picture](https://drive.google.com/uc?export=view&id=1eCsjNAtjXuXfqBLxeEnsBpOikUO06msr)\n","\n","<br>\n","\n","---\n","---\n","\n","<div class=\"alert alert-block alert-warning\">\n","<h1><span style=\"color:green\"> Foundations of Artificial Intelligence<br> (AI701-Fall2022) </span><h1>\n","\n","<h2><span style=\"color:green\"> Lab-09 </span><h2>\n","</div>\n","\n","---\n","---"]},{"cell_type":"markdown","metadata":{"id":"AhLr4lNpYPH3"},"source":["## Part 1. Neural Networks (NNs)\n","**Neural networks**, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another.\n","\n","Neural networks rely on training data to learn and improve their accuracy over time. However, once these learning algorithms are fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high velocity. Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts. One of the most well-known neural networks is Google’s search algorithm.\n","\n","\n","<br>\n","\n","![Colah'blog](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork-WHITEBG.png)\n","<center>Deep neural network </center> \n","\n","<center> <a href=\"https://www.ibm.com/cloud/learn/neural-networks\" title=\"IBM Neural Networks blog\">\n","Image Source</a></center>\n"]},{"cell_type":"markdown","source":["<h3>Step 1.</h3>We import the dataset from the sklearn library with built-in sample datasets. We will use the train and test split function and the the accuracy and confusion matrix metrics from the sklearn library to split the data into train and test samples and to evaluate the results, respectively. Then, we will use the already built model for Neural Network from the sklearn library. The imports will look like this:"],"metadata":{"id":"dCJn76JrizrH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1AcpBsi6AxzK"},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import confusion_matrix, accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"fATHaxeL6Mkh"},"source":["<h3>Step.2</h3>\n","We will load the dataset from the sklearn library to a local variable. Now, all the data from the library is in the dataset variable. Let’s look at the code given below: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4sykwc16Mki"},"outputs":[],"source":["dataset = load_digits()"]},{"cell_type":"markdown","source":["<h3>Step.3</h3>\n","We will split the dataset into train and test using the sklearn library. We will use a 80-20 split, in which 80 percent data will be train data and 20 percent of the data will be test data. Let’s look at the code given below:"],"metadata":{"id":"r1S2tG0ekWVx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0poUt_Eu6Mkj"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.20, random_state=4)"]},{"cell_type":"code","source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2H9ik28hkJDn","executionInfo":{"status":"ok","timestamp":1666607796556,"user_tz":-240,"elapsed":6,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"406cf714-d060-47c5-9a17-93cd2c4e668c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1437, 64), (360, 64), (1437,), (360,))"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"2I3prjokdncH"},"source":["<h3>Step.4</h3>\n","We will make the Neural Network classifier, and call it NN. We will use all the default parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3RyHNVPdncN"},"outputs":[],"source":["NN = MLPClassifier()"]},{"cell_type":"markdown","metadata":{"id":"YF4py5sS6Mkk"},"source":["<h3>Step.5</h3>\n","We will train the model on the training data and the training labels."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWUBu8aofd9J","outputId":"34432c63-55bb-431f-8363-eea005b6d527","executionInfo":{"status":"ok","timestamp":1666607767889,"user_tz":-240,"elapsed":2137,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLPClassifier()"]},"metadata":{},"execution_count":5}],"source":["NN.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"dCHZo4hX_KGF"},"source":["<h3>Step.6</h3>\n","We will use the testing data and testing labels to test the model."]},{"cell_type":"code","source":["y_pred = NN.predict(x_test)\n","y_pred.shape"],"metadata":{"id":"7Y5iMnRNl6DO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666607835805,"user_tz":-240,"elapsed":459,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"f02e1ea0-9795-481b-89be-84c14652c518"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(360,)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"1-PABcjOAx0u"},"source":["<h3>Step.7</h3>\n","We will use the accuracy function to get the accuracy of the model and use the confusion matrix function to find the confusion matrix. Then, we will multiply accuracy by 100 to scale it out of 100."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Cf6ozWaC-2g"},"outputs":[],"source":["accuracy = accuracy_score(y_test,y_pred)*100\n","confusion_mat = confusion_matrix(y_test,y_pred)"]},{"cell_type":"markdown","source":["<h3>Step.8</h3>\n","Finally, we will print the results."],"metadata":{"id":"h-1C_PcQrWJU"}},{"cell_type":"code","source":["print(\"Accuracy for Neural Network is:\",accuracy)\n","print(\"Confusion Matrix\")\n","print(confusion_mat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhEcN-LSrUNS","outputId":"58022514-95b4-4bec-b28b-56ac493360ba","executionInfo":{"status":"ok","timestamp":1666607846598,"user_tz":-240,"elapsed":295,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for Neural Network is: 97.5\n","Confusion Matrix\n","[[38  0  0  0  0  0  0  0  0  0]\n"," [ 0 30  1  0  0  0  0  1  0  0]\n"," [ 0  1 40  0  0  0  0  0  0  0]\n"," [ 0  0  0 32  0  1  0  0  0  0]\n"," [ 0  1  0  0 36  0  0  0  0  0]\n"," [ 0  0  0  1  0 37  0  0  0  0]\n"," [ 0  0  0  0  0  0 34  0  1  0]\n"," [ 0  0  0  0  0  0  0 38  0  0]\n"," [ 0  2  0  0  0  0  0  0 31  0]\n"," [ 0  0  0  0  0  0  0  0  0 35]]\n"]}]},{"cell_type":"markdown","source":["<h2>Tasks</h2>\n","After understanding the above code you are required to perform the following tasks and submit the solution on student portal before the start of next week's lab."],"metadata":{"id":"6tgv5OwrAJvD"}},{"cell_type":"markdown","source":["<h3>Task 1: Analyze the dataset</h3>\n","Previously we loaded the digits dataset in Step.2 but did not analyze it before feeding it to the model. The good practice is to analyze and understand the dataset before feeding it to the model. In task 1 you are required to do the following tasks programmatically.\n","\n","\n","1.   Explore digit data set. What are total number of examples in the dataset? What are the dimensions of image? What is the maximum and minimum pixel value in entire training data set?  Plot one image from digits dataset.\n","\n","\n"],"metadata":{"id":"Zpcg9RYXAWLB"}},{"cell_type":"code","source":["#TASK1 \n","import matplotlib.pyplot as plt\n","import numpy as np\n","# Number of examples in the dataset\n","print(\"Number of total examples: \",len(dataset.data))\n","# Plotting the first image from the dataset\n","plt.gray()\n","plt.matshow(dataset.images[0])\n","plt.show()\n","#Printing the dimensions of the image\n","print(\"Shape of the image is: \", dataset.images[0].shape)\n","#Printing max and min pixel value\n","smallest_pixel = None\n","biggest_pixel = None\n","for i in range(len(dataset.data)):\n","  smallest = np.amin(dataset.images[i])\n","  biggest = np.amax(dataset.images[i])\n","  if smallest_pixel is None:\n","    smallest_pixel = smallest\n","    biggest_pixel = smallest\n","  elif smallest < smallest_pixel:\n","    smallest_pixel = smallest\n","  elif biggest > biggest_pixel:\n","    biggest_pixel = biggest\n","print(\"The smallest pixel of the entire dataset is: \", smallest_pixel)\n","print(\"The biggest pixel of the entire dataset is: \", biggest_pixel)"],"metadata":{"id":"oEkrZxJYrvwj","colab":{"base_uri":"https://localhost:8080/","height":362},"outputId":"120e338a-b1a4-47ab-ad58-9f972e5fcc8b","executionInfo":{"status":"ok","timestamp":1666607882549,"user_tz":-240,"elapsed":381,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of total examples:  1797\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 288x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Shape of the image is:  (8, 8)\n","The smallest pixel of the entire dataset is:  0.0\n","The biggest pixel of the entire dataset is:  16.0\n"]}]},{"cell_type":"markdown","source":["<h3>Task.2 Analyze the Confusion Matrix </h3>\n","In the model evaluation step we constructed the confusion matrix. By visualizing the confusion matrix which digits are predicted wrong by the model and how many incorrect examples are from each class?\n","Hint: See the respective column and rows for each non-diagonal (non-zero entries) in the matrix."],"metadata":{"id":"l1LD69xPA0WI"}},{"cell_type":"markdown","source":["### Part 2: PyTorch Deep Dive\n","In this part we will get accousmted to PyTorch with basic introduction. First we will install the PyTorch and understand the concepts of tensors and the numerous possible operations that a user can compute with the various functionalities offered in PyTorch. We will then use PyTorch to build a Neural Network. \n","\n","## Introduction\n","PyTorch is one of the best options for deep learning, which is available as an open-source deep learning framework that was first introduced and developed by Facebook's AI Research lab (FAIR). The primary aim of the torch environment library developed was to construct highly effective models that could produce the best possible results and solutions for a particular task. The applications of the PyTorch library extend from machine learning applications to natural language processing and computer vision tasks. Apart from these use cases, they are also utilized in a number of software structures. Some of the examples include Uber's Pyro, Tesla Autopilot, Hugging Face Transformers, PyTorch Lightning, and Catalyst."],"metadata":{"id":"Yv5sNKvE8Bpc"}},{"cell_type":"markdown","source":["## Installation\n","To install PyTorch, go to the official PyTorch website and set up the build according to your system. Please follow this [link](https://pytorch.org/) to reach the website."],"metadata":{"id":"TC4rGiLK_Fpp"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"760mIj3HTT-o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Getting Started: What are tensors?\n","PyTorch is similar to NumPy library, in the NumPy library, we have multi-dimensional arrays whereas in PyTorch, we have tensors. So, let’s first understand what tensors are. Tensors are multidimensional arrays. And PyTorch tensors are similar to NumPy’s n-dimensional arrays. We can use these tensors on a GPU as well (this is not the case with NumPy arrays). This is a major advantage of using tensors.\n"],"metadata":{"id":"qRiXQ7-AYe3S"}},{"cell_type":"code","source":["# importing libraries\n","import numpy as np\n","import torch"],"metadata":{"id":"royZaNBjY7qa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let’s see how we can assign a variable in NumPy as well as PyTorch\n","# initializing a numpy array\n","a = np.array(1)\n","\n","# initializing a tensor\n","b = torch.tensor(1)\n","\n","print(a)\n","print(b)\n","type(a), type(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1DiVCOmZYX5","outputId":"6cc52871-a96d-4510-cde9-b3d1f0d55b66","executionInfo":{"status":"ok","timestamp":1666608102637,"user_tz":-240,"elapsed":2,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","tensor(1)\n"]},{"output_type":"execute_result","data":{"text/plain":["(numpy.ndarray, torch.Tensor)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["#### Mathematical Operations"],"metadata":{"id":"IWIp4aeHb-C4"}},{"cell_type":"code","source":["#using numpy arrays\n","a = np.array(2)\n","b = np.array(1)\n","# addition\n","print(a+b)\n","\n","# subtraction\n","print(b-a)\n","\n","# multiplication\n","print(a*b)\n","\n","# division\n","print(a/b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6K50d5pgcCN1","outputId":"28f18eba-e423-4bd5-c433-9905ffa89c6c","executionInfo":{"status":"ok","timestamp":1666608110535,"user_tz":-240,"elapsed":1762,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","-1\n","2\n","2.0\n"]}]},{"cell_type":"code","source":["#using tensors\n","a = torch.tensor(2)\n","b = torch.tensor(1)\n","print(a,b)\n","\n","# addition\n","print(a+b)\n","\n","# subtraction\n","print(b-a)\n","\n","# multiplication\n","print(a*b)\n","\n","# division\n","print(a/b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnptP5_EcZSu","outputId":"fd724f34-ee58-412f-a2cb-12b09c1d5f51","executionInfo":{"status":"ok","timestamp":1666608121023,"user_tz":-240,"elapsed":305,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2) tensor(1)\n","tensor(3)\n","tensor(-1)\n","tensor(2)\n","tensor(2.)\n"]}]},{"cell_type":"code","source":["#matrix initialization\n","# matrix of zeros\n","a = torch.zeros((3,3))\n","print(a)\n","print(a.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdvULPDHceNc","outputId":"deb010ae-1cbd-4e59-a088-ae73fd5d4d4b","executionInfo":{"status":"ok","timestamp":1666608128601,"user_tz":-240,"elapsed":2,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","torch.Size([3, 3])\n"]}]},{"cell_type":"code","source":["# While building a neural network, we randomly initialize the weights for the model. So, let’s see how we can initialize a matrix with random numbers\n","# setting the random seed for pytorch\n","torch.manual_seed(42)\n","# matrix of random numbers\n","a = torch.randn(3,3)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GroAa3VWc60Y","outputId":"430d3d24-f99c-4efd-84f1-f2ab397fa5cc","executionInfo":{"status":"ok","timestamp":1666608132753,"user_tz":-240,"elapsed":1,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3367,  0.1288,  0.2345],\n","        [ 0.2303, -1.1229, -0.1863],\n","        [ 2.2082, -0.6380,  0.4617]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Numpy Operations\n","- Dot Product and Matrix Multiplication\n","- Hadamad Product and Element-wise multiplication"],"metadata":{"id":"B-aPQKERsGBX"}},{"cell_type":"code","source":["import numpy as np\n","a = np.array([[1,2],[3,4]])\n","b = np.array([[5,6],[7,8]])\n","print(a)\n","print()\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQHfyOH0sDHq","executionInfo":{"status":"ok","timestamp":1666610334251,"user_tz":-240,"elapsed":335,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"6d974463-db9d-4be4-e8c9-04ce8da7b4b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2]\n"," [3 4]]\n","\n","[[5 6]\n"," [7 8]]\n"]}]},{"cell_type":"code","source":["# Dot Product and Matrix Multiplication\n","np.dot(a,b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJQYXdm_svPn","executionInfo":{"status":"ok","timestamp":1666610357979,"user_tz":-240,"elapsed":310,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"d698b3b7-1b22-4fe9-fb0d-57459423c309"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[19, 22],\n","       [43, 50]])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# Dot Product and Matrix Multiplication\n","a.dot(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81LARG-xtP7l","executionInfo":{"status":"ok","timestamp":1666610170872,"user_tz":-240,"elapsed":463,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"99b32e80-f517-49f2-fd8f-bb799d915e88"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[19, 22],\n","       [43, 50]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# Dot Product and Matrix Multiplication\n","a@b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGLuCjvRtHm4","executionInfo":{"status":"ok","timestamp":1666610140263,"user_tz":-240,"elapsed":1084,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"81aa9210-17fe-4c33-a96f-2a91be61a768"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[19, 22],\n","       [43, 50]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# Hadamad Product and Element-wise multiplication\n","a*b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDKOicQHt48H","executionInfo":{"status":"ok","timestamp":1666610339104,"user_tz":-240,"elapsed":347,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"ce5a8c23-6c50-4d12-935a-458a042b26cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 5, 12],\n","       [21, 32]])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Hadamad Product and Element-wise multiplication\n","np.multiply(a,b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7A_f_4Mstn2","executionInfo":{"status":"ok","timestamp":1666610031158,"user_tz":-240,"elapsed":328,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"8987be26-1854-4f7b-e67b-b03759d206d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 5, 12],\n","       [21, 32]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["a = torch.from_numpy(a)\n","b = torch.from_numpy(b)\n","print(a)\n","print()\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYcX4lb1tqxQ","executionInfo":{"status":"ok","timestamp":1666610409621,"user_tz":-240,"elapsed":554,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"556c9021-c79b-4d97-f1f4-f86a45f71c6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n","\n","tensor([[5, 6],\n","        [7, 8]])\n"]}]},{"cell_type":"code","source":["# Dot Product and Matrix Multiplication\n","torch.mm(a,b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJNqLYCAu1JP","executionInfo":{"status":"ok","timestamp":1666610591709,"user_tz":-240,"elapsed":653,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"ee6c4d34-8322-4b86-f524-d9db09f5c5bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19, 22],\n","        [43, 50]])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["# Dot Product and Matrix Multiplication\n","a@b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-S-KhqCuOXR","executionInfo":{"status":"ok","timestamp":1666610429626,"user_tz":-240,"elapsed":552,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"38ea38f7-f78d-43bc-a065-4a3354e36737"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19, 22],\n","        [43, 50]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Hadamad Product and Element-wise multiplication\n","a.mul(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryK-gxqguaiv","executionInfo":{"status":"ok","timestamp":1666610479635,"user_tz":-240,"elapsed":797,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"7dac1498-9138-4941-f858-25b375be8af3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 5, 12],\n","        [21, 32]])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# Hadamad Product and Element-wise multiplication\n","torch.mul(a,b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGK__MxfuSgX","executionInfo":{"status":"ok","timestamp":1666610447372,"user_tz":-240,"elapsed":447,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"b4f399d9-d708-410c-fde4-fc5113130f37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 5, 12],\n","        [21, 32]])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Hadamad Product and Element-wise multiplication\n","a*b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bjCpq1Gt1NR","executionInfo":{"status":"ok","timestamp":1666610413530,"user_tz":-240,"elapsed":284,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"fa869442-c837-43da-ab6d-f1d037d145f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 5, 12],\n","        [21, 32]])"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["#### Matrix Operations"],"metadata":{"id":"Z3LU9SszdWn3"}},{"cell_type":"code","source":["torch.manual_seed(42)\n","a = torch.randn(3,3)\n","b = torch.randn(3,3)\n","\n","# matrix addition\n","print(torch.add(a,b), '\\n')\n","\n","# matrix subtraction\n","print(torch.sub(a,b), '\\n')\n","\n","# matrix multiplication\n","print(torch.mm(a,b), '\\n') # similar to dot product in NumPy\n","\n","# matrix division\n","print(torch.div(a,b))\n","\n","# matrix transpose\n","torch.t(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQu9FjuCdLym","outputId":"84584b36-096a-47b6-de6e-d20863c685b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.6040,  0.6637,  1.0438],\n","        [ 1.3406, -2.8127, -1.1753],\n","        [ 3.1662,  0.6841,  1.2788]]) \n","\n","tensor([[ 0.0693, -0.4061, -0.5749],\n","        [-0.8800,  0.5669,  0.8026],\n","        [ 1.2502, -1.9601, -0.3555]]) \n","\n","tensor([[ 0.4576,  0.2724,  0.3367],\n","        [-1.3636,  1.7743,  1.1446],\n","        [ 0.3243,  2.8696,  2.7954]]) \n","\n","tensor([[ 1.2594,  0.2408,  0.2897],\n","        [ 0.2075,  0.6645,  0.1884],\n","        [ 2.3051, -0.4826,  0.5649]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3367,  0.2303,  2.2082],\n","        [ 0.1288, -1.1229, -0.6380],\n","        [ 0.2345, -0.1863,  0.4617]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["#### Concatenating Tensors"],"metadata":{"id":"rURReciXdxm_"}},{"cell_type":"code","source":["# initializing two tensors\n","a = torch.tensor([[1,2],[3,4]])\n","b = torch.tensor([[5,6],[7,8]])\n","print(a, '\\n')\n","print(b, '\\n')\n","\n","# concatenating vertically\n","print()\n","print(torch.cat((a,b),dim=0))\n","\n","# concatenating horizontally\n","torch.cat((a,b),dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4hCUABMEdgoY","outputId":"21d50412-c53c-416c-92ef-b02f2ee69437","executionInfo":{"status":"ok","timestamp":1666610654985,"user_tz":-240,"elapsed":550,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]]) \n","\n","tensor([[5, 6],\n","        [7, 8]]) \n","\n","\n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 5, 6],\n","        [3, 4, 7, 8]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["#### Reshaping Tensors"],"metadata":{"id":"HhPB-DIveGF8"}},{"cell_type":"code","source":["# setting the random seed for pytorch\n","torch.manual_seed(42)\n","# initializing tensor\n","a = torch.randn(2,4)\n","print(a)\n","a.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ej7h8VGaeFP_","outputId":"50af3264-669d-4ce7-97bf-653eb7eb1ca5","executionInfo":{"status":"ok","timestamp":1666610664806,"user_tz":-240,"elapsed":303,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.3367,  0.1288,  0.2345,  0.2303],\n","        [-1.1229, -0.1863,  2.2082, -0.6380]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 4])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["# reshaping tensor\n","b = a.reshape(1,8)\n","print(b)\n","b.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNLRUVWOeWEj","outputId":"1baa4f8e-9f2c-41f0-825a-0c99dbce2439","executionInfo":{"status":"ok","timestamp":1666610669663,"user_tz":-240,"elapsed":347,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 8])"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["#### NumPy to Tensors Conversion"],"metadata":{"id":"N_h_Am3Geb6g"}},{"cell_type":"code","source":["# initializing a numpy array\n","a = np.array([[1,2],[3,4]])\n","print(a, '\\n')\n","\n","# converting the numpy array to tensor\n","tensor = torch.from_numpy(a)\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgjjXz69egL2","outputId":"21206296-6dd1-436b-fd45-2ce520999a90","executionInfo":{"status":"ok","timestamp":1666610675378,"user_tz":-240,"elapsed":295,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2]\n"," [3 4]] \n","\n","tensor([[1, 2],\n","        [3, 4]])\n"]}]},{"cell_type":"markdown","source":["### Common PyTorch Modules\n","#### Autograd\n","PyTorch uses a technique called automatic differentiation. It records all the operations that we are performing and replays it backward to compute gradients. This technique helps us to save time on each epoch as we are calculating the gradients on the forward pass itself.\n","\n","Let’s look at an example to understand how the gradients are computed."],"metadata":{"id":"3i7PbLvDeo7V"}},{"cell_type":"code","source":["# initializing a tensor\n","a = torch.ones((2,2), requires_grad=True)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvOSoaCne3kS","outputId":"925ec21b-3989-48cd-f85f-af69e078886f","executionInfo":{"status":"ok","timestamp":1666611623501,"user_tz":-240,"elapsed":324,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["We have initialized a tensor. Specifying requires_grad as True will make sure that the gradients are stored for this particular tensor whenever we perform some operation on it. Let’s now perform some operations on the defined tensor."],"metadata":{"id":"qoXpsJ_Be9D7"}},{"cell_type":"code","source":["b = a + 5\n","b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlDfrEUky8HL","executionInfo":{"status":"ok","timestamp":1666611664120,"user_tz":-240,"elapsed":373,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"8b166256-f144-4053-cdea-598864e4201c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[6., 6.],\n","        [6., 6.]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# performing operations on the tensor\n","c = b.mean()\n","c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGDE-UK1fCJT","outputId":"7ba5c491-7b9d-43c2-a91a-80f1f286f8d3","executionInfo":{"status":"ok","timestamp":1666611685744,"user_tz":-240,"elapsed":494,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6., grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["#### Task: Compute derivative of 'c' with respect to 'a' on paper and verify the answer below.\n","\n","PartialDerv(c)/PartialDerv(a) = \n","Since c is a constant and a is a matrix we will have PartialDerv(c)/PartialDerv(a1), PartialDerv(c)/PartialDerv(a2) .. PartialDerv(c)/PartialDerv(a4)\n","\n","c = mean[(a1 + 5),(a2 + 5),(a3 + 5),(a4 + 5)]\n","\n","c = 1/4 [a1 + a2 + a3 + a4 + 20]\n","\n","\n","PartialDerv(c)/PartialDerv(a1) = 1/4.   \n","PartialDerv(c)/PartialDerv(a2) = 1/4.   \n","PartialDerv(c)/PartialDerv(a3) = 1/4.   \n","PartialDerv(c)/PartialDerv(a4) = 1/4.   "],"metadata":{"id":"YD34DOyekeVA"}},{"cell_type":"code","source":["# back propagating\n","c.backward()\n","\n","# computing gradients\n","print(a.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zodOP0GksNf","outputId":"7054d399-e283-4bbc-e3ca-1ac1a3c7918a","executionInfo":{"status":"ok","timestamp":1666613797438,"user_tz":-240,"elapsed":571,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2500, 0.2500],\n","        [0.2500, 0.2500]])\n"]}]},{"cell_type":"markdown","source":["#### Optim Module\n","The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models."],"metadata":{"id":"jNdktkuKplKN"}},{"cell_type":"code","source":["# importing the optim module\n","from torch import optim\n","\n","# adam\n","# adam = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# sgd\n","# SGD = optim.SGD(model.parameters(), lr=learning_rate)"],"metadata":{"id":"wRBzrK2bpt2n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### nn Module\n","nn Module defines a set of functions, similar to the layers of a neural network, which takes the input from the previous state and produces an output. Let's build a neural network from scratch that will help us understand how PyTorch works in a practical way."],"metadata":{"id":"YQ_YDFnVp8FD"}},{"cell_type":"code","source":["# first initialize the input and output\n","#Input tensor\n","X = torch.Tensor([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n","\n","#Output\n","y = torch.Tensor([[1],[1],[0]])\n","\n","print(X, '\\n')\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOrZecRip95g","outputId":"973f466d-bed4-452a-af34-fb8193c52f6a","executionInfo":{"status":"ok","timestamp":1666613910323,"user_tz":-240,"elapsed":395,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 0.],\n","        [1., 0., 1., 1.],\n","        [0., 1., 0., 1.]]) \n","\n","tensor([[1.],\n","        [1.],\n","        [0.]])\n"]}]},{"cell_type":"markdown","source":["We will define the sigmoid function which will act as the activation function and the derivative of the sigmoid function which will help us in the backpropagation step."],"metadata":{"id":"FtIn1-8wrw81"}},{"cell_type":"code","source":["X.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQIwHkPGa3du","outputId":"4ab628ed-3fb3-452f-8b85-5bccca375105","executionInfo":{"status":"ok","timestamp":1666613914896,"user_tz":-240,"elapsed":373,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["### Task\n","Find the derivative of sigmoid activation function on paper and verify the below formula that function returns.\n","\n","Answer: Apply qoutient rule to the sigmoid function and reach the desired results. To be solved on white board in session (if required)."],"metadata":{"id":"uDhmrl3BgvQ7"}},{"cell_type":"code","source":["#Sigmoid Function\n","def sigmoid (x):\n","    return 1/(1 + torch.exp(-x))\n","\n","#Derivative of Sigmoid Function/\n","def derivatives_sigmoid(x):\n","    return sigmoid(x) * (1 - sigmoid(x))\n"],"metadata":{"id":"FIlwN41XrpcV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialize the parameters for our model including the number of epochs, learning rate, weights, and biases."],"metadata":{"id":"YoCQ6lwlr4uz"}},{"cell_type":"code","source":["#Variable initialization\n","epoch=7000 #Setting training iterations\n","lr=0.1 #Setting learning rate\n","inputlayer_neurons = X.shape[1] #number of features in data set\n","hiddenlayer_neurons = 3 #number of hidden layer neurons\n","output_neurons = 1 #number of neurons in output layer\n","\n","#weight and bias initialization\n","wh=torch.randn(inputlayer_neurons, hiddenlayer_neurons).type(torch.FloatTensor)\n","bh=torch.randn(1, hiddenlayer_neurons).type(torch.FloatTensor)\n","wout=torch.randn(hiddenlayer_neurons, output_neurons)\n","bout=torch.randn(1, output_neurons)"],"metadata":{"id":"NwXQxIQ9r8xH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wh.shape, bh.shape, wout.shape, bout.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJhsTew58oJK","executionInfo":{"status":"ok","timestamp":1666614232206,"user_tz":-240,"elapsed":678,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}},"outputId":"834a9db4-192f-4e42-bacb-88cc6e8f8628"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 3]),\n"," torch.Size([1, 3]),\n"," torch.Size([3, 1]),\n"," torch.Size([1, 1]))"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["bout"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNATPbQsbIBH","outputId":"d2653b74-0e68-4f35-c377-bbb7e56d7cdc","executionInfo":{"status":"ok","timestamp":1666614244146,"user_tz":-240,"elapsed":294,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.5227]])"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["We randomly initialized the weights and biases using the .randn() function which we saw earlier. Finally, we will create a neural network with a single hidden layer and an input and an output layer.\n","\n","In the forward propagation step, we are calculating the output and finally, in the backward propagation step, we are calculating the error. We will then update the weights and biases using this error."],"metadata":{"id":"w4_f0kxEsN9J"}},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"vB-EyarA90kS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(epoch):\n","    #Forward Propogation\n","    hidden_layer_input1 = torch.mm(X, wh)\n","    hidden_layer_input = hidden_layer_input1 + bh\n","    hidden_layer_activations = sigmoid(hidden_layer_input)\n","\n","    output_layer_input1 = torch.mm(hidden_layer_activations, wout)\n","    output_layer_input = output_layer_input1 + bout\n","    output = sigmoid(output_layer_input)\n","\n","    #Backpropagation\n","    E = y-output\n","\n","    # Getting Derivatives\n","    slope_output_layer = derivatives_sigmoid(output)\n","    slope_hidden_layer = derivatives_sigmoid(hidden_layer_activations)\n","\n","    d_output = E * slope_output_layer\n","    Error_at_hidden_layer = torch.mm(d_output, wout.t())\n","    d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n","\n","    # Updating Weights\n","    wout += torch.mm(hidden_layer_activations.t(), d_output) *lr\n","    bout += d_output.sum() *lr\n","    wh += torch.mm(X.t(), d_hiddenlayer) *lr\n","    bh += d_output.sum() *lr"],"metadata":{"id":"AQS2nSExsGeg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('actual :\\n', y, '\\n')\n","print('predicted :\\n', output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STGIqOuXsawU","outputId":"3071861c-13c5-4e1f-ab15-52c283c9d82f","executionInfo":{"status":"ok","timestamp":1666615277792,"user_tz":-240,"elapsed":414,"user":{"displayName":"Ex Why Zee XYZ","userId":"16700964037974729982"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["actual :\n"," tensor([[1.],\n","        [1.],\n","        [0.]]) \n","\n","predicted :\n"," tensor([[0.9980],\n","        [0.9964],\n","        [0.0053]])\n"]}]},{"cell_type":"markdown","source":["###Task \n","a. Change the neural netowork architecture by changing the hyperparameters and analyze and report the results: \n","1. Hidden layer neurons\n","2. Hidden layers\n","3. Learning rate\n","\n","b. The predicted probabilities are not the same if we re-train the model (along initialization cell). Comment on why this is happening? \n","\n","\n","Answer: due to random initialization\n","\n","c. Reproduce the exact same probabilities for a specific set of hyperparameters.\n","\n","\n","Answer: Add torch.maunal_seed(some value) before initialization"],"metadata":{"id":"iUcop5_pgH_m"}},{"cell_type":"markdown","source":["### Resources\n","1. The PyTorch [homepage](https://pytorch.org)\n","2. [Crash course](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) in PyTorch\n","3. Justin Johnson’s [repository](https://github.com/jcjohnson/pytorch-examples) that introduces fundamental PyTorch concepts through self-contained examples.\n","4. Tons of resources in this [list](https://github.com/ritchieng/the-incredible-pytorch)."],"metadata":{"id":"Er79LsGQYU8k"}},{"cell_type":"markdown","source":["### Congratulations you have successfully completed Lab 09.\n","\n","---\n","\n"],"metadata":{"id":"qPyQQShaBLUk"}}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}